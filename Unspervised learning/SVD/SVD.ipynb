{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model without applying SVD:\n",
      "Classification Report without SVD:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suyash Tambe\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model without applying SVD\n",
    "print(\"Model without applying SVD:\")\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report without SVD:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy_without_svd = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model after applying SVD:\n",
      "Classification Report with SVD:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Variance explained by SVD components: 0.9763362752389951\n",
      "Accuracy without SVD: 1.0\n",
      "Accuracy with SVD: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Apply SVD\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "X_train_svd = svd.fit_transform(X_train)\n",
    "X_test_svd = svd.transform(X_test)\n",
    "\n",
    "# Train and test the model after applying SVD\n",
    "print(\"\\nModel after applying SVD:\")\n",
    "model_svd = LogisticRegression()\n",
    "model_svd.fit(X_train_svd, y_train)\n",
    "y_pred_svd = model_svd.predict(X_test_svd)\n",
    "print(\"Classification Report with SVD:\")\n",
    "print(classification_report(y_test, y_pred_svd))\n",
    "accuracy_with_svd = accuracy_score(y_test, y_pred_svd)\n",
    "\n",
    "# Calculate variance explained by SVD components\n",
    "variance_explained = svd.explained_variance_ratio_.sum()\n",
    "\n",
    "# Print variance and accuracy\n",
    "print(\"\\nVariance explained by SVD components:\", variance_explained)\n",
    "print(\"Accuracy without SVD:\", accuracy_without_svd)\n",
    "print(\"Accuracy with SVD:\", accuracy_with_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model without applying SVD:\n",
    "\n",
    "Classification Report without SVD: This section presents the precision, recall, and F1-score for each class, along with the support (number of instances) for each class in the test set. In this case, all metrics are perfect (1.0), indicating that the model correctly classified all instances of each class. The overall accuracy is also 1.0, meaning that all predictions made by the model are correct.\n",
    "\n",
    "\n",
    "Model after applying SVD:\n",
    "\n",
    "Classification Report with SVD: Similar to the previous section, this section presents the precision, recall, and F1-score for each class, along with the support for each class in the test set. Again, all metrics are perfect (1.0), indicating that the model correctly classified all instances of each class. The overall accuracy is also 1.0, indicating that all predictions made by the model after applying SVD are correct.\n",
    "\n",
    "\n",
    "Variance explained by SVD components:\n",
    "\n",
    "This section provides the variance explained by the SVD components. In this case, the two SVD components explain approximately 97.6% of the variance in the original dataset. This indicates that these components capture most of the variability in the data, despite reducing the dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High Dimensinal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suyash Tambe\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model without applying SVD:\n",
      "Classification Report without SVD:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      2267\n",
      "           1       0.93      0.97      0.95      2603\n",
      "           2       0.87      0.86      0.87      2350\n",
      "           3       0.86      0.86      0.86      2383\n",
      "           4       0.88      0.91      0.89      2144\n",
      "           5       0.88      0.72      0.79      2107\n",
      "           6       0.90      0.94      0.92      2294\n",
      "           7       0.90      0.90      0.90      2455\n",
      "           8       0.80      0.84      0.82      2196\n",
      "           9       0.85      0.87      0.86      2301\n",
      "\n",
      "    accuracy                           0.88     23100\n",
      "   macro avg       0.88      0.88      0.88     23100\n",
      "weighted avg       0.88      0.88      0.88     23100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suyash Tambe\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model without applying SVD\n",
    "print(\"Model without applying SVD:\")\n",
    "model = LogisticRegression(max_iter=10)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report without SVD:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy_without_svd = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model after applying SVD:\n",
      "Classification Report with SVD:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      2267\n",
      "           1       0.93      0.96      0.94      2603\n",
      "           2       0.87      0.86      0.86      2350\n",
      "           3       0.85      0.86      0.85      2383\n",
      "           4       0.87      0.90      0.89      2144\n",
      "           5       0.87      0.71      0.78      2107\n",
      "           6       0.89      0.93      0.91      2294\n",
      "           7       0.90      0.90      0.90      2455\n",
      "           8       0.79      0.83      0.81      2196\n",
      "           9       0.84      0.86      0.85      2301\n",
      "\n",
      "    accuracy                           0.88     23100\n",
      "   macro avg       0.88      0.87      0.87     23100\n",
      "weighted avg       0.88      0.88      0.88     23100\n",
      "\n",
      "\n",
      "Variance explained by SVD components: 0.8255508394529177\n",
      "Accuracy without SVD: 0.8822943722943722\n",
      "Accuracy with SVD: 0.8774458874458875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suyash Tambe\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Apply SVD\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "X_train_svd = svd.fit_transform(X_train)\n",
    "X_test_svd = svd.transform(X_test)\n",
    "\n",
    "# Train and test the model after applying SVD\n",
    "print(\"\\nModel after applying SVD:\")\n",
    "model_svd = LogisticRegression(max_iter=10)\n",
    "model_svd.fit(X_train_svd, y_train)\n",
    "y_pred_svd = model_svd.predict(X_test_svd)\n",
    "print(\"Classification Report with SVD:\")\n",
    "print(classification_report(y_test, y_pred_svd))\n",
    "accuracy_with_svd = accuracy_score(y_test, y_pred_svd)\n",
    "\n",
    "# Calculate variance explained by SVD components\n",
    "variance_explained = svd.explained_variance_ratio_.sum()\n",
    "\n",
    "# Print variance and accuracy\n",
    "print(\"\\nVariance explained by SVD components:\", variance_explained)\n",
    "print(\"Accuracy without SVD:\", accuracy_without_svd)\n",
    "print(\"Accuracy with SVD:\", accuracy_with_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without SVD:\n",
    "\n",
    " The accuracy score indicates the proportion of correctly classified instances out of the total number of instances. Here, the accuracy is 1.0, meaning all predictions made by the model are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SVD:\n",
    "\n",
    "Accuracy with SVD: The accuracy score is again 1.0, indicating perfect classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

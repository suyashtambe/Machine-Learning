{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Without applying LDA\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred_without_lda = knn_classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_train_lda = lda.fit_transform(X_train_scaled, y_train)\n",
    "X_test_lda = lda.transform(X_test_scaled)\n",
    "\n",
    "# Train and test the model after applying LDA\n",
    "knn_classifier_lda = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_classifier_lda.fit(X_train_lda, y_train)\n",
    "y_pred_with_lda = knn_classifier_lda.predict(X_test_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report without LDA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      2267\n",
      "           1       0.94      0.99      0.97      2603\n",
      "           2       0.94      0.93      0.94      2350\n",
      "           3       0.92      0.94      0.93      2383\n",
      "           4       0.95      0.93      0.94      2144\n",
      "           5       0.94      0.92      0.93      2107\n",
      "           6       0.97      0.97      0.97      2294\n",
      "           7       0.94      0.92      0.93      2455\n",
      "           8       0.97      0.89      0.93      2196\n",
      "           9       0.91      0.92      0.92      2301\n",
      "\n",
      "    accuracy                           0.94     23100\n",
      "   macro avg       0.94      0.94      0.94     23100\n",
      "weighted avg       0.94      0.94      0.94     23100\n",
      "\n",
      "\n",
      "Classification Report with LDA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      2267\n",
      "           1       0.92      0.97      0.94      2603\n",
      "           2       0.89      0.90      0.90      2350\n",
      "           3       0.88      0.86      0.87      2383\n",
      "           4       0.89      0.92      0.90      2144\n",
      "           5       0.87      0.86      0.86      2107\n",
      "           6       0.95      0.94      0.95      2294\n",
      "           7       0.94      0.91      0.93      2455\n",
      "           8       0.89      0.82      0.85      2196\n",
      "           9       0.90      0.88      0.89      2301\n",
      "\n",
      "    accuracy                           0.91     23100\n",
      "   macro avg       0.91      0.91      0.91     23100\n",
      "weighted avg       0.91      0.91      0.91     23100\n",
      "\n",
      "\n",
      "Accuracy without LDA: 0.9428138528138528\n",
      "Accuracy with LDA: 0.9068398268398269\n"
     ]
    }
   ],
   "source": [
    "# Classification report without LDA\n",
    "print(\"Classification Report without LDA:\")\n",
    "print(classification_report(y_test, y_pred_without_lda))\n",
    "accuracy_without_lda = accuracy_score(y_test, y_pred_without_lda)\n",
    "\n",
    "\n",
    "\n",
    "# Classification report with LDA\n",
    "print(\"\\nClassification Report with LDA:\")\n",
    "print(classification_report(y_test, y_pred_with_lda))\n",
    "accuracy_with_lda = accuracy_score(y_test, y_pred_with_lda)\n",
    "\n",
    "\n",
    "print(\"\\nAccuracy without LDA:\", accuracy_without_lda)\n",
    "print(\"Accuracy with LDA:\", accuracy_with_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without LDA:\n",
    "\n",
    "The model achieved an accuracy of 94.28%. Precision, recall, and F1-score for each class are relatively high, indicating good performance across all classes.\n",
    "\n",
    "With LDA:\n",
    "\n",
    "After applying Linear Discriminant Analysis, the model's accuracy decreased slightly to 90.68%. This indicates that LDA may have reduced the model's ability to distinguish between classes compared to the original dataset. Additionally, there is a decrease in precision, recall, and F1-score for some classes, indicating a slight decrease in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "High Dimnesional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suyash Tambe\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without applying LDA\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred_without_lda = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)  # Reduce to 9 components for MNIST\n",
    "X_train_lda = lda.fit_transform(X_train_scaled, y_train)\n",
    "X_test_lda = lda.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the model after applying LDA\n",
    "knn_classifier_lda = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier_lda.fit(X_train_lda, y_train)\n",
    "y_pred_with_lda = knn_classifier_lda.predict(X_test_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without LDA:\n",
      "Variance: pixel1      0.000000\n",
      "pixel2      0.000000\n",
      "pixel3      0.000000\n",
      "pixel4      0.000000\n",
      "pixel5      0.000000\n",
      "              ...   \n",
      "pixel780    0.081962\n",
      "pixel781    0.000000\n",
      "pixel782    0.000000\n",
      "pixel783    0.000000\n",
      "pixel784    0.000000\n",
      "Length: 784, dtype: float32\n",
      "Accuracy: 0.9428138528138528\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      2267\n",
      "           1       0.94      0.99      0.97      2603\n",
      "           2       0.94      0.93      0.94      2350\n",
      "           3       0.92      0.94      0.93      2383\n",
      "           4       0.95      0.93      0.94      2144\n",
      "           5       0.94      0.92      0.93      2107\n",
      "           6       0.97      0.97      0.97      2294\n",
      "           7       0.94      0.92      0.93      2455\n",
      "           8       0.97      0.89      0.93      2196\n",
      "           9       0.91      0.92      0.92      2301\n",
      "\n",
      "    accuracy                           0.94     23100\n",
      "   macro avg       0.94      0.94      0.94     23100\n",
      "weighted avg       0.94      0.94      0.94     23100\n",
      "\n",
      "\n",
      "With LDA:\n",
      "Variance: 2.8161333\n",
      "Accuracy: 0.9068398268398269\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      2267\n",
      "           1       0.92      0.97      0.94      2603\n",
      "           2       0.89      0.90      0.90      2350\n",
      "           3       0.88      0.86      0.87      2383\n",
      "           4       0.89      0.92      0.90      2144\n",
      "           5       0.87      0.86      0.86      2107\n",
      "           6       0.95      0.94      0.95      2294\n",
      "           7       0.94      0.91      0.93      2455\n",
      "           8       0.89      0.82      0.85      2196\n",
      "           9       0.90      0.88      0.89      2301\n",
      "\n",
      "    accuracy                           0.91     23100\n",
      "   macro avg       0.91      0.91      0.91     23100\n",
      "weighted avg       0.91      0.91      0.91     23100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report without LDA\n",
    "accuracy_without_lda = accuracy_score(y_test, y_pred_without_lda)\n",
    "variance_without_lda = X_train.var()\n",
    "\n",
    "print(\"Without LDA:\")\n",
    "print(\"Variance:\", variance_without_lda)\n",
    "print(\"Accuracy:\", accuracy_without_lda)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_without_lda))\n",
    "\n",
    "\n",
    "# Classification report with LDA\n",
    "accuracy_with_lda = accuracy_score(y_test, y_pred_with_lda)\n",
    "variance_with_lda = X_train_lda.var()\n",
    "\n",
    "print(\"\\nWith LDA:\")\n",
    "print(\"Variance:\", variance_with_lda)\n",
    "print(\"Accuracy:\", accuracy_with_lda)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_with_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With LDA\n",
    "\n",
    "Variance:\n",
    "\n",
    "The variance after applying LDA is shown as a single value (2.8161333 in this case), which represents the variance of the transformed data after dimensionality reduction. This reduced variance indicates that the data has been compressed into fewer dimensions while preserving the most important information.\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "With LDA: \n",
    "\n",
    "The accuracy of the classifier with LDA is 90.68%, which is slightly lower compared to the accuracy without LDA. This suggests that although LDA reduces the dimensionality of the data, it may discard some information that was helpful for classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without LDA\n",
    "\n",
    "Variance:\n",
    "\n",
    " The variance values for individual pixels are shown, where most of the pixels have a variance of 0, indicating low variance within each pixel across the dataset.\n",
    "\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "Without LDA: \n",
    "The accuracy of the classifier without LDA is 94.28%, indicating that the model correctly classifies approximately 94.28% of the test data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "LDA effectively reduces the dimensionality of the feature space while preserving the discriminatory information needed for classification.\n",
    "The improvement in performance (precision, recall, and F1-score) with LDA is more prominent in the smaller dataset compared to the larger MNIST dataset.\n",
    "The results indicate that LDA can enhance the performance of machine learning models, especially in scenarios with high-dimensional datasets like the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
